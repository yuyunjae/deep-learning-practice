{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7bb341e",
   "metadata": {},
   "source": [
    "# 미니 배치(Mini Batch)와 데이터 로더(DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "1c203e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset, Dataset\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "# CUDA 사용 시(여기서는 CPU 고정 권장이므로 선택)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # 아래 두 줄은 환경과 버전에 따라 선택\n",
    "    # torch.backends.cuda.matmul.allow_tf32 = False\n",
    "    # torch.backends.cudnn.allow_tf32 = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "4af6bb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[73, 80, 75], [93, 88, 93], [89, 91, 90], [96, 98, 100], [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "4f6728d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 TensorDataset의 입력으로 사용하고 dataset으로 저장\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "\n",
    "# g = torch.Generator().manual_seed(42)\n",
    "# dataLoader = DataLoader(dataset, batch_size=2, shuffle=True, generator=g)\n",
    "dataLoader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "635d83bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0/20, Cost: 7937.602539\n",
      "Epoch:    0/20, Cost: 5775.528320\n",
      "Epoch:    0/20, Cost: 1678.240967\n",
      "Epoch:    1/20, Cost: 273.867584\n",
      "Epoch:    1/20, Cost: 73.110306\n",
      "Epoch:    1/20, Cost: 3.771547\n",
      "Epoch:    2/20, Cost: 28.770439\n",
      "Epoch:    2/20, Cost: 1.102020\n",
      "Epoch:    2/20, Cost: 0.018248\n",
      "Epoch:    3/20, Cost: 4.035028\n",
      "Epoch:    3/20, Cost: 4.250602\n",
      "Epoch:    3/20, Cost: 3.958240\n",
      "Epoch:    4/20, Cost: 3.035414\n",
      "Epoch:    4/20, Cost: 4.048670\n",
      "Epoch:    4/20, Cost: 1.960239\n",
      "Epoch:    5/20, Cost: 2.819942\n",
      "Epoch:    5/20, Cost: 4.009200\n",
      "Epoch:    5/20, Cost: 2.040997\n",
      "Epoch:    6/20, Cost: 3.645667\n",
      "Epoch:    6/20, Cost: 0.428303\n",
      "Epoch:    6/20, Cost: 7.242025\n",
      "Epoch:    7/20, Cost: 3.668132\n",
      "Epoch:    7/20, Cost: 3.111837\n",
      "Epoch:    7/20, Cost: 2.968807\n",
      "Epoch:    8/20, Cost: 1.356676\n",
      "Epoch:    8/20, Cost: 4.052970\n",
      "Epoch:    8/20, Cost: 3.584163\n",
      "Epoch:    9/20, Cost: 3.512377\n",
      "Epoch:    9/20, Cost: 3.366941\n",
      "Epoch:    9/20, Cost: 0.073125\n",
      "Epoch:   10/20, Cost: 0.770133\n",
      "Epoch:   10/20, Cost: 5.542919\n",
      "Epoch:   10/20, Cost: 5.720853\n",
      "Epoch:   11/20, Cost: 5.327495\n",
      "Epoch:   11/20, Cost: 2.340384\n",
      "Epoch:   11/20, Cost: 3.268363\n",
      "Epoch:   12/20, Cost: 0.359328\n",
      "Epoch:   12/20, Cost: 7.068606\n",
      "Epoch:   12/20, Cost: 4.890202\n",
      "Epoch:   13/20, Cost: 1.099829\n",
      "Epoch:   13/20, Cost: 4.131986\n",
      "Epoch:   13/20, Cost: 3.901011\n",
      "Epoch:   14/20, Cost: 3.122023\n",
      "Epoch:   14/20, Cost: 3.167735\n",
      "Epoch:   14/20, Cost: 3.044103\n",
      "Epoch:   15/20, Cost: 1.329109\n",
      "Epoch:   15/20, Cost: 3.010649\n",
      "Epoch:   15/20, Cost: 5.487801\n",
      "Epoch:   16/20, Cost: 3.112036\n",
      "Epoch:   16/20, Cost: 3.471340\n",
      "Epoch:   16/20, Cost: 5.106817\n",
      "Epoch:   17/20, Cost: 1.473305\n",
      "Epoch:   17/20, Cost: 3.423557\n",
      "Epoch:   17/20, Cost: 5.186920\n",
      "Epoch:   18/20, Cost: 1.369056\n",
      "Epoch:   18/20, Cost: 4.030637\n",
      "Epoch:   18/20, Cost: 3.692606\n",
      "Epoch:   19/20, Cost: 5.106310\n",
      "Epoch:   19/20, Cost: 4.862840\n",
      "Epoch:   19/20, Cost: 0.019145\n",
      "Epoch:   20/20, Cost: 4.065109\n",
      "Epoch:   20/20, Cost: 2.550371\n",
      "Epoch:   20/20, Cost: 0.051830\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(3, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
    "\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    for batch_idx, samples in enumerate(dataLoader):\n",
    "        # print(batch_idx, samples)\n",
    "        x_train, y_train = samples\n",
    "        # print(x_train.shape, y_train.shape)\n",
    "        \n",
    "        # H(x) 계산\n",
    "        prediction = model(x_train)\n",
    "        \n",
    "        cost = F.mse_loss(prediction, y_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('Epoch: {:4d}/{}, Cost: {:.6f}'.format(epoch, nb_epochs, cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "4be78022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0/20, Cost: 13637.417969\n",
      "Epoch:    0/20, Cost: 2035.193115\n",
      "Epoch:    0/20, Cost: 580.398499\n",
      "Epoch:    1/20, Cost: 376.903015\n",
      "Epoch:    1/20, Cost: 151.049225\n",
      "Epoch:    1/20, Cost: 39.716576\n",
      "Epoch:    2/20, Cost: 15.853495\n",
      "Epoch:    2/20, Cost: 6.992236\n",
      "Epoch:    2/20, Cost: 1.867033\n",
      "Epoch:    3/20, Cost: 0.409047\n",
      "Epoch:    3/20, Cost: 5.195969\n",
      "Epoch:    3/20, Cost: 6.783936\n",
      "Epoch:    4/20, Cost: 3.021986\n",
      "Epoch:    4/20, Cost: 3.929235\n",
      "Epoch:    4/20, Cost: 0.461374\n",
      "Epoch:    5/20, Cost: 3.522270\n",
      "Epoch:    5/20, Cost: 2.206404\n",
      "Epoch:    5/20, Cost: 3.202274\n",
      "Epoch:    6/20, Cost: 4.330459\n",
      "Epoch:    6/20, Cost: 2.630559\n",
      "Epoch:    6/20, Cost: 0.031720\n",
      "Epoch:    7/20, Cost: 2.637102\n",
      "Epoch:    7/20, Cost: 1.699211\n",
      "Epoch:    7/20, Cost: 6.615451\n",
      "Epoch:    8/20, Cost: 1.593786\n",
      "Epoch:    8/20, Cost: 4.989443\n",
      "Epoch:    8/20, Cost: 4.372359\n",
      "Epoch:    9/20, Cost: 1.190410\n",
      "Epoch:    9/20, Cost: 4.023237\n",
      "Epoch:    9/20, Cost: 5.780277\n",
      "Epoch:   10/20, Cost: 3.113744\n",
      "Epoch:   10/20, Cost: 1.496351\n",
      "Epoch:   10/20, Cost: 6.152725\n",
      "Epoch:   11/20, Cost: 3.387016\n",
      "Epoch:   11/20, Cost: 3.474214\n",
      "Epoch:   11/20, Cost: 0.042944\n",
      "Epoch:   12/20, Cost: 0.731119\n",
      "Epoch:   12/20, Cost: 5.583770\n",
      "Epoch:   12/20, Cost: 5.652590\n",
      "Epoch:   13/20, Cost: 4.245217\n",
      "Epoch:   13/20, Cost: 0.772802\n",
      "Epoch:   13/20, Cost: 4.714788\n",
      "Epoch:   14/20, Cost: 3.610071\n",
      "Epoch:   14/20, Cost: 1.324254\n",
      "Epoch:   14/20, Cost: 5.544209\n",
      "Epoch:   15/20, Cost: 1.396152\n",
      "Epoch:   15/20, Cost: 3.086011\n",
      "Epoch:   15/20, Cost: 5.450333\n",
      "Epoch:   16/20, Cost: 2.342355\n",
      "Epoch:   16/20, Cost: 2.791930\n",
      "Epoch:   16/20, Cost: 7.597368\n",
      "Epoch:   17/20, Cost: 1.319443\n",
      "Epoch:   17/20, Cost: 2.966380\n",
      "Epoch:   17/20, Cost: 5.352880\n",
      "Epoch:   18/20, Cost: 3.142285\n",
      "Epoch:   18/20, Cost: 3.424927\n",
      "Epoch:   18/20, Cost: 5.112059\n",
      "Epoch:   19/20, Cost: 1.464864\n",
      "Epoch:   19/20, Cost: 4.713200\n",
      "Epoch:   19/20, Cost: 6.049006\n",
      "Epoch:   20/20, Cost: 4.938926\n",
      "Epoch:   20/20, Cost: 2.448053\n",
      "Epoch:   20/20, Cost: 3.252658\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# ---- 재현성 설정 ----\n",
    "seed = 42\n",
    "\n",
    "# 가능하면 CUDA 비결정성 방지용 환경변수 (CUDA 사용 시 유효)\n",
    "# os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"  # 또는 \":4096:8\"\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "# CUDA 사용 시(여기서는 CPU 고정 권장이므로 선택)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # 아래 두 줄은 환경과 버전에 따라 선택\n",
    "    # torch.backends.cuda.matmul.allow_tf32 = False\n",
    "    # torch.backends.cudnn.allow_tf32 = False\n",
    "\n",
    "# (가장 확실하게) CPU로 고정\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "# ---- 데이터 ----\n",
    "x_train = torch.tensor([[73, 80, 75],\n",
    "                        [93, 88, 93],\n",
    "                        [89, 91, 90],\n",
    "                        [96, 98, 100],\n",
    "                        [73, 66, 70]], dtype=torch.float32)\n",
    "y_train = torch.tensor([[152],\n",
    "                        [185],\n",
    "                        [180],\n",
    "                        [196],\n",
    "                        [142]], dtype=torch.float32)\n",
    "\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "\n",
    "# DataLoader 셔플 재현성 보장용 Generator\n",
    "g = torch.Generator().manual_seed(seed)\n",
    "\n",
    "dataLoader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    generator=g,\n",
    "    num_workers=0,     # 멀티워커 비결정성 방지 (필요시 worker_init_fn으로 시드 고정)\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "# ---- 모델/옵티마이저 ----\n",
    "# 모델 초기화도 전역 시드에 의해 결정적\n",
    "model = nn.Linear(3, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
    "\n",
    "# ---- 학습 ----\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    for batch_idx, samples in enumerate(dataLoader):\n",
    "        xb, yb = samples \n",
    "\n",
    "        pred = model(xb)\n",
    "        cost = F.mse_loss(pred, yb)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Epoch: {epoch:4d}/{nb_epochs}, Cost: {cost.item():.6f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "1204b816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 입력이 73, 80, 75일 때의 예측값 : tensor([[153.1775]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 임의의 입력 [73, 80, 75]를 선언\n",
    "new_var =  torch.FloatTensor([[73, 80, 75]]) \n",
    "# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "pred_y = model(new_var) \n",
    "print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9df59a",
   "metadata": {},
   "source": [
    "# 커스텀 데이터셋 만드는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404504ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        # 생성자부분 (데이터 셋 전처리)\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        # 데이터 셋의 길이 (총 셈플의 수)\n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 데이터 셋에서 특정 1개의 샘플을 가져오는 함수\n",
    "        pass\n",
    "    \n",
    "# torch.utils.data.Dataset은 추상 클래스여서 __len__이랑 __getitem__을 무조건 구현해주어야함.\n",
    "# 아니면 그냥 TensorDataset 사용하삼.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "0aa2f9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x_data = [[73, 80, 75],\n",
    "                   [93, 88, 93],\n",
    "                   [89, 91, 90],\n",
    "                   [96, 98, 100],\n",
    "                   [73, 66, 70]]\n",
    "        self.y_data = [[152], [185], [180], [196], [142]]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_data[idx])\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c454d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomDataset()\n",
    "dataLoader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "# print(dataset.__len__())\n",
    "\n",
    "model = torch.nn.Linear(3, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "4c531b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20, Cost: 35803.921875\n",
      "Epoch    0/20, Cost: 16515.566406\n",
      "Epoch    0/20, Cost: 2256.199951\n",
      "Epoch    1/20, Cost: 1425.250488\n",
      "Epoch    1/20, Cost: 427.543610\n",
      "Epoch    1/20, Cost: 132.186142\n",
      "Epoch    2/20, Cost: 51.370708\n",
      "Epoch    2/20, Cost: 28.593304\n",
      "Epoch    2/20, Cost: 0.445428\n",
      "Epoch    3/20, Cost: 9.191752\n",
      "Epoch    3/20, Cost: 5.633094\n",
      "Epoch    3/20, Cost: 0.976640\n",
      "Epoch    4/20, Cost: 5.322802\n",
      "Epoch    4/20, Cost: 4.743402\n",
      "Epoch    4/20, Cost: 1.807387\n",
      "Epoch    5/20, Cost: 6.002551\n",
      "Epoch    5/20, Cost: 0.579418\n",
      "Epoch    5/20, Cost: 8.797900\n",
      "Epoch    6/20, Cost: 4.970479\n",
      "Epoch    6/20, Cost: 3.671367\n",
      "Epoch    6/20, Cost: 6.464517\n",
      "Epoch    7/20, Cost: 3.655384\n",
      "Epoch    7/20, Cost: 4.759625\n",
      "Epoch    7/20, Cost: 3.824538\n",
      "Epoch    8/20, Cost: 5.676812\n",
      "Epoch    8/20, Cost: 3.522624\n",
      "Epoch    8/20, Cost: 1.063193\n",
      "Epoch    9/20, Cost: 0.531859\n",
      "Epoch    9/20, Cost: 9.495720\n",
      "Epoch    9/20, Cost: 6.467854\n",
      "Epoch   10/20, Cost: 7.966233\n",
      "Epoch   10/20, Cost: 3.648458\n",
      "Epoch   10/20, Cost: 3.519689\n",
      "Epoch   11/20, Cost: 0.083491\n",
      "Epoch   11/20, Cost: 10.976756\n",
      "Epoch   11/20, Cost: 5.764952\n",
      "Epoch   12/20, Cost: 1.263589\n",
      "Epoch   12/20, Cost: 5.121383\n",
      "Epoch   12/20, Cost: 7.848992\n",
      "Epoch   13/20, Cost: 5.174066\n",
      "Epoch   13/20, Cost: 3.582886\n",
      "Epoch   13/20, Cost: 6.315708\n",
      "Epoch   14/20, Cost: 3.624499\n",
      "Epoch   14/20, Cost: 3.291339\n",
      "Epoch   14/20, Cost: 6.688257\n",
      "Epoch   15/20, Cost: 3.525737\n",
      "Epoch   15/20, Cost: 3.347986\n",
      "Epoch   15/20, Cost: 9.667833\n",
      "Epoch   16/20, Cost: 2.686737\n",
      "Epoch   16/20, Cost: 5.575770\n",
      "Epoch   16/20, Cost: 5.533650\n",
      "Epoch   17/20, Cost: 3.577259\n",
      "Epoch   17/20, Cost: 4.647596\n",
      "Epoch   17/20, Cost: 3.750241\n",
      "Epoch   18/20, Cost: 7.281796\n",
      "Epoch   18/20, Cost: 6.035169\n",
      "Epoch   18/20, Cost: 0.349826\n",
      "Epoch   19/20, Cost: 5.048674\n",
      "Epoch   19/20, Cost: 4.389298\n",
      "Epoch   19/20, Cost: 0.834757\n",
      "Epoch   20/20, Cost: 3.900419\n",
      "Epoch   20/20, Cost: 5.379817\n",
      "Epoch   20/20, Cost: 0.888661\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    for batch_idx, samples in enumerate(dataLoader):\n",
    "        x_t, y_t = samples\n",
    "        \n",
    "        prediction = model(x_t)\n",
    "        \n",
    "        cost = F.mse_loss(prediction, y_t)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('Epoch {:4d}/{}, Cost: {:.6f}'.format(epoch, nb_epochs, cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "f45ae612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([153.6559], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test = torch.FloatTensor([73, 80, 75])\n",
    "test_result = model(test)\n",
    "\n",
    "print(test_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
