{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b372c1c7",
   "metadata": {},
   "source": [
    "### Logistic Regression using nn.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70f1ee61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x210f048c6d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86a001bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1,2],\n",
    "          [2,3],\n",
    "          [3,1],\n",
    "          [4,3],\n",
    "          [5,3],\n",
    "          [6,2]]\n",
    "y_data = [[0],\n",
    "          [0],\n",
    "          [0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [1]]\n",
    "\n",
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a530d885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequatially compute Linear(Wx+b), then Sigmoid (1/(1+e^(-x)))\n",
    "model = nn.Sequential(nn.Linear(2,1), nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9626015d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4020],\n",
       "        [0.4147],\n",
       "        [0.6556],\n",
       "        [0.5948],\n",
       "        [0.6788],\n",
       "        [0.8061]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eae94c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost : 1.188488 Accuracy 50.00%\n",
      "Epoch   10/1000 Cost : 0.648468 Accuracy 83.33%\n",
      "Epoch   20/1000 Cost : 0.548321 Accuracy 83.33%\n",
      "Epoch   30/1000 Cost : 0.456483 Accuracy 83.33%\n",
      "Epoch   40/1000 Cost : 0.372049 Accuracy 83.33%\n",
      "Epoch   50/1000 Cost : 0.292564 Accuracy 83.33%\n",
      "Epoch   60/1000 Cost : 0.223404 Accuracy 83.33%\n",
      "Epoch   70/1000 Cost : 0.175517 Accuracy 100.00%\n",
      "Epoch   80/1000 Cost : 0.152655 Accuracy 100.00%\n",
      "Epoch   90/1000 Cost : 0.140972 Accuracy 100.00%\n",
      "Epoch  100/1000 Cost : 0.131600 Accuracy 100.00%\n",
      "Epoch  110/1000 Cost : 0.123428 Accuracy 100.00%\n",
      "Epoch  120/1000 Cost : 0.116229 Accuracy 100.00%\n",
      "Epoch  130/1000 Cost : 0.109840 Accuracy 100.00%\n",
      "Epoch  140/1000 Cost : 0.104131 Accuracy 100.00%\n",
      "Epoch  150/1000 Cost : 0.098998 Accuracy 100.00%\n",
      "Epoch  160/1000 Cost : 0.094360 Accuracy 100.00%\n",
      "Epoch  170/1000 Cost : 0.090146 Accuracy 100.00%\n",
      "Epoch  180/1000 Cost : 0.086302 Accuracy 100.00%\n",
      "Epoch  190/1000 Cost : 0.082780 Accuracy 100.00%\n",
      "Epoch  200/1000 Cost : 0.079542 Accuracy 100.00%\n",
      "Epoch  210/1000 Cost : 0.076553 Accuracy 100.00%\n",
      "Epoch  220/1000 Cost : 0.073787 Accuracy 100.00%\n",
      "Epoch  230/1000 Cost : 0.071218 Accuracy 100.00%\n",
      "Epoch  240/1000 Cost : 0.068826 Accuracy 100.00%\n",
      "Epoch  250/1000 Cost : 0.066594 Accuracy 100.00%\n",
      "Epoch  260/1000 Cost : 0.064506 Accuracy 100.00%\n",
      "Epoch  270/1000 Cost : 0.062547 Accuracy 100.00%\n",
      "Epoch  280/1000 Cost : 0.060707 Accuracy 100.00%\n",
      "Epoch  290/1000 Cost : 0.058974 Accuracy 100.00%\n",
      "Epoch  300/1000 Cost : 0.057340 Accuracy 100.00%\n",
      "Epoch  310/1000 Cost : 0.055796 Accuracy 100.00%\n",
      "Epoch  320/1000 Cost : 0.054334 Accuracy 100.00%\n",
      "Epoch  330/1000 Cost : 0.052949 Accuracy 100.00%\n",
      "Epoch  340/1000 Cost : 0.051634 Accuracy 100.00%\n",
      "Epoch  350/1000 Cost : 0.050385 Accuracy 100.00%\n",
      "Epoch  360/1000 Cost : 0.049195 Accuracy 100.00%\n",
      "Epoch  370/1000 Cost : 0.048062 Accuracy 100.00%\n",
      "Epoch  380/1000 Cost : 0.046980 Accuracy 100.00%\n",
      "Epoch  390/1000 Cost : 0.045947 Accuracy 100.00%\n",
      "Epoch  400/1000 Cost : 0.044960 Accuracy 100.00%\n",
      "Epoch  410/1000 Cost : 0.044014 Accuracy 100.00%\n",
      "Epoch  420/1000 Cost : 0.043109 Accuracy 100.00%\n",
      "Epoch  430/1000 Cost : 0.042240 Accuracy 100.00%\n",
      "Epoch  440/1000 Cost : 0.041407 Accuracy 100.00%\n",
      "Epoch  450/1000 Cost : 0.040606 Accuracy 100.00%\n",
      "Epoch  460/1000 Cost : 0.039836 Accuracy 100.00%\n",
      "Epoch  470/1000 Cost : 0.039095 Accuracy 100.00%\n",
      "Epoch  480/1000 Cost : 0.038382 Accuracy 100.00%\n",
      "Epoch  490/1000 Cost : 0.037695 Accuracy 100.00%\n",
      "Epoch  500/1000 Cost : 0.037032 Accuracy 100.00%\n",
      "Epoch  510/1000 Cost : 0.036393 Accuracy 100.00%\n",
      "Epoch  520/1000 Cost : 0.035775 Accuracy 100.00%\n",
      "Epoch  530/1000 Cost : 0.035179 Accuracy 100.00%\n",
      "Epoch  540/1000 Cost : 0.034602 Accuracy 100.00%\n",
      "Epoch  550/1000 Cost : 0.034044 Accuracy 100.00%\n",
      "Epoch  560/1000 Cost : 0.033504 Accuracy 100.00%\n",
      "Epoch  570/1000 Cost : 0.032981 Accuracy 100.00%\n",
      "Epoch  580/1000 Cost : 0.032475 Accuracy 100.00%\n",
      "Epoch  590/1000 Cost : 0.031984 Accuracy 100.00%\n",
      "Epoch  600/1000 Cost : 0.031508 Accuracy 100.00%\n",
      "Epoch  610/1000 Cost : 0.031046 Accuracy 100.00%\n",
      "Epoch  620/1000 Cost : 0.030597 Accuracy 100.00%\n",
      "Epoch  630/1000 Cost : 0.030162 Accuracy 100.00%\n",
      "Epoch  640/1000 Cost : 0.029738 Accuracy 100.00%\n",
      "Epoch  650/1000 Cost : 0.029327 Accuracy 100.00%\n",
      "Epoch  660/1000 Cost : 0.028927 Accuracy 100.00%\n",
      "Epoch  670/1000 Cost : 0.028538 Accuracy 100.00%\n",
      "Epoch  680/1000 Cost : 0.028159 Accuracy 100.00%\n",
      "Epoch  690/1000 Cost : 0.027791 Accuracy 100.00%\n",
      "Epoch  700/1000 Cost : 0.027432 Accuracy 100.00%\n",
      "Epoch  710/1000 Cost : 0.027082 Accuracy 100.00%\n",
      "Epoch  720/1000 Cost : 0.026741 Accuracy 100.00%\n",
      "Epoch  730/1000 Cost : 0.026409 Accuracy 100.00%\n",
      "Epoch  740/1000 Cost : 0.026085 Accuracy 100.00%\n",
      "Epoch  750/1000 Cost : 0.025768 Accuracy 100.00%\n",
      "Epoch  760/1000 Cost : 0.025460 Accuracy 100.00%\n",
      "Epoch  770/1000 Cost : 0.025159 Accuracy 100.00%\n",
      "Epoch  780/1000 Cost : 0.024865 Accuracy 100.00%\n",
      "Epoch  790/1000 Cost : 0.024578 Accuracy 100.00%\n",
      "Epoch  800/1000 Cost : 0.024297 Accuracy 100.00%\n",
      "Epoch  810/1000 Cost : 0.024023 Accuracy 100.00%\n",
      "Epoch  820/1000 Cost : 0.023755 Accuracy 100.00%\n",
      "Epoch  830/1000 Cost : 0.023493 Accuracy 100.00%\n",
      "Epoch  840/1000 Cost : 0.023237 Accuracy 100.00%\n",
      "Epoch  850/1000 Cost : 0.022986 Accuracy 100.00%\n",
      "Epoch  860/1000 Cost : 0.022741 Accuracy 100.00%\n",
      "Epoch  870/1000 Cost : 0.022501 Accuracy 100.00%\n",
      "Epoch  880/1000 Cost : 0.022266 Accuracy 100.00%\n",
      "Epoch  890/1000 Cost : 0.022035 Accuracy 100.00%\n",
      "Epoch  900/1000 Cost : 0.021810 Accuracy 100.00%\n",
      "Epoch  910/1000 Cost : 0.021589 Accuracy 100.00%\n",
      "Epoch  920/1000 Cost : 0.021373 Accuracy 100.00%\n",
      "Epoch  930/1000 Cost : 0.021161 Accuracy 100.00%\n",
      "Epoch  940/1000 Cost : 0.020953 Accuracy 100.00%\n",
      "Epoch  950/1000 Cost : 0.020749 Accuracy 100.00%\n",
      "Epoch  960/1000 Cost : 0.020550 Accuracy 100.00%\n",
      "Epoch  970/1000 Cost : 0.020354 Accuracy 100.00%\n",
      "Epoch  980/1000 Cost : 0.020162 Accuracy 100.00%\n",
      "Epoch  990/1000 Cost : 0.019973 Accuracy 100.00%\n",
      "Epoch 1000/1000 Cost : 0.019788 Accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr = 1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    hypothesis = model(x_train)\n",
    "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        # make prediction\n",
    "        prediction = hypothesis >= torch.FloatTensor([0.5])\n",
    "        # check if the prediction is true or not\n",
    "        TPN = prediction.float() == y_train\n",
    "        # calculate acc value\n",
    "        acc = TPN.sum().item() / len(TPN)\n",
    "\n",
    "        print('Epoch {:4d}/{} Cost : {:.6f} Accuracy {:2.2f}%'.format(\n",
    "            epoch, nb_epochs, cost.item(), acc*100\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcb0b7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7427e-04],\n",
       "        [3.1512e-02],\n",
       "        [3.8850e-02],\n",
       "        [9.5635e-01],\n",
       "        [9.9824e-01],\n",
       "        [9.9969e-01]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a85d27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[3.2561, 1.5196]], requires_grad=True), Parameter containing:\n",
      "tensor([-14.4964], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1232daff",
   "metadata": {},
   "source": [
    "### Logistic Regression using class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e79ce5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x210f048c6d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7174e21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1,2],\n",
    "          [2,3],\n",
    "          [3,1],\n",
    "          [4,3],\n",
    "          [5,3],\n",
    "          [6,2]]\n",
    "y_data = [[0],\n",
    "          [0],\n",
    "          [0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [1]]\n",
    "\n",
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f94dc79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(2,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x))\n",
    "    \n",
    "\n",
    "model = BinaryClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5c7c1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost 0.539713 Acc 83.33%\n",
      "Epoch   10/1000 Cost 0.614852 Acc 66.67%\n",
      "Epoch   20/1000 Cost 0.441875 Acc 66.67%\n",
      "Epoch   30/1000 Cost 0.373145 Acc 83.33%\n",
      "Epoch   40/1000 Cost 0.316358 Acc 83.33%\n",
      "Epoch   50/1000 Cost 0.266094 Acc 83.33%\n",
      "Epoch   60/1000 Cost 0.220498 Acc 100.00%\n",
      "Epoch   70/1000 Cost 0.182095 Acc 100.00%\n",
      "Epoch   80/1000 Cost 0.157299 Acc 100.00%\n",
      "Epoch   90/1000 Cost 0.144091 Acc 100.00%\n",
      "Epoch  100/1000 Cost 0.134272 Acc 100.00%\n",
      "Epoch  110/1000 Cost 0.125769 Acc 100.00%\n",
      "Epoch  120/1000 Cost 0.118297 Acc 100.00%\n",
      "Epoch  130/1000 Cost 0.111680 Acc 100.00%\n",
      "Epoch  140/1000 Cost 0.105779 Acc 100.00%\n",
      "Epoch  150/1000 Cost 0.100483 Acc 100.00%\n",
      "Epoch  160/1000 Cost 0.095704 Acc 100.00%\n",
      "Epoch  170/1000 Cost 0.091369 Acc 100.00%\n",
      "Epoch  180/1000 Cost 0.087420 Acc 100.00%\n",
      "Epoch  190/1000 Cost 0.083806 Acc 100.00%\n",
      "Epoch  200/1000 Cost 0.080486 Acc 100.00%\n",
      "Epoch  210/1000 Cost 0.077425 Acc 100.00%\n",
      "Epoch  220/1000 Cost 0.074595 Acc 100.00%\n",
      "Epoch  230/1000 Cost 0.071969 Acc 100.00%\n",
      "Epoch  240/1000 Cost 0.069526 Acc 100.00%\n",
      "Epoch  250/1000 Cost 0.067248 Acc 100.00%\n",
      "Epoch  260/1000 Cost 0.065118 Acc 100.00%\n",
      "Epoch  270/1000 Cost 0.063122 Acc 100.00%\n",
      "Epoch  280/1000 Cost 0.061247 Acc 100.00%\n",
      "Epoch  290/1000 Cost 0.059483 Acc 100.00%\n",
      "Epoch  300/1000 Cost 0.057820 Acc 100.00%\n",
      "Epoch  310/1000 Cost 0.056250 Acc 100.00%\n",
      "Epoch  320/1000 Cost 0.054764 Acc 100.00%\n",
      "Epoch  330/1000 Cost 0.053357 Acc 100.00%\n",
      "Epoch  340/1000 Cost 0.052022 Acc 100.00%\n",
      "Epoch  350/1000 Cost 0.050753 Acc 100.00%\n",
      "Epoch  360/1000 Cost 0.049546 Acc 100.00%\n",
      "Epoch  370/1000 Cost 0.048396 Acc 100.00%\n",
      "Epoch  380/1000 Cost 0.047299 Acc 100.00%\n",
      "Epoch  390/1000 Cost 0.046252 Acc 100.00%\n",
      "Epoch  400/1000 Cost 0.045251 Acc 100.00%\n",
      "Epoch  410/1000 Cost 0.044294 Acc 100.00%\n",
      "Epoch  420/1000 Cost 0.043376 Acc 100.00%\n",
      "Epoch  430/1000 Cost 0.042497 Acc 100.00%\n",
      "Epoch  440/1000 Cost 0.041653 Acc 100.00%\n",
      "Epoch  450/1000 Cost 0.040843 Acc 100.00%\n",
      "Epoch  460/1000 Cost 0.040064 Acc 100.00%\n",
      "Epoch  470/1000 Cost 0.039315 Acc 100.00%\n",
      "Epoch  480/1000 Cost 0.038593 Acc 100.00%\n",
      "Epoch  490/1000 Cost 0.037898 Acc 100.00%\n",
      "Epoch  500/1000 Cost 0.037228 Acc 100.00%\n",
      "Epoch  510/1000 Cost 0.036582 Acc 100.00%\n",
      "Epoch  520/1000 Cost 0.035958 Acc 100.00%\n",
      "Epoch  530/1000 Cost 0.035356 Acc 100.00%\n",
      "Epoch  540/1000 Cost 0.034773 Acc 100.00%\n",
      "Epoch  550/1000 Cost 0.034210 Acc 100.00%\n",
      "Epoch  560/1000 Cost 0.033664 Acc 100.00%\n",
      "Epoch  570/1000 Cost 0.033137 Acc 100.00%\n",
      "Epoch  580/1000 Cost 0.032625 Acc 100.00%\n",
      "Epoch  590/1000 Cost 0.032130 Acc 100.00%\n",
      "Epoch  600/1000 Cost 0.031649 Acc 100.00%\n",
      "Epoch  610/1000 Cost 0.031183 Acc 100.00%\n",
      "Epoch  620/1000 Cost 0.030730 Acc 100.00%\n",
      "Epoch  630/1000 Cost 0.030291 Acc 100.00%\n",
      "Epoch  640/1000 Cost 0.029864 Acc 100.00%\n",
      "Epoch  650/1000 Cost 0.029449 Acc 100.00%\n",
      "Epoch  660/1000 Cost 0.029046 Acc 100.00%\n",
      "Epoch  670/1000 Cost 0.028654 Acc 100.00%\n",
      "Epoch  680/1000 Cost 0.028272 Acc 100.00%\n",
      "Epoch  690/1000 Cost 0.027900 Acc 100.00%\n",
      "Epoch  700/1000 Cost 0.027538 Acc 100.00%\n",
      "Epoch  710/1000 Cost 0.027186 Acc 100.00%\n",
      "Epoch  720/1000 Cost 0.026842 Acc 100.00%\n",
      "Epoch  730/1000 Cost 0.026507 Acc 100.00%\n",
      "Epoch  740/1000 Cost 0.026181 Acc 100.00%\n",
      "Epoch  750/1000 Cost 0.025862 Acc 100.00%\n",
      "Epoch  760/1000 Cost 0.025552 Acc 100.00%\n",
      "Epoch  770/1000 Cost 0.025248 Acc 100.00%\n",
      "Epoch  780/1000 Cost 0.024952 Acc 100.00%\n",
      "Epoch  790/1000 Cost 0.024663 Acc 100.00%\n",
      "Epoch  800/1000 Cost 0.024381 Acc 100.00%\n",
      "Epoch  810/1000 Cost 0.024104 Acc 100.00%\n",
      "Epoch  820/1000 Cost 0.023835 Acc 100.00%\n",
      "Epoch  830/1000 Cost 0.023571 Acc 100.00%\n",
      "Epoch  840/1000 Cost 0.023313 Acc 100.00%\n",
      "Epoch  850/1000 Cost 0.023061 Acc 100.00%\n",
      "Epoch  860/1000 Cost 0.022814 Acc 100.00%\n",
      "Epoch  870/1000 Cost 0.022572 Acc 100.00%\n",
      "Epoch  880/1000 Cost 0.022336 Acc 100.00%\n",
      "Epoch  890/1000 Cost 0.022104 Acc 100.00%\n",
      "Epoch  900/1000 Cost 0.021877 Acc 100.00%\n",
      "Epoch  910/1000 Cost 0.021655 Acc 100.00%\n",
      "Epoch  920/1000 Cost 0.021437 Acc 100.00%\n",
      "Epoch  930/1000 Cost 0.021224 Acc 100.00%\n",
      "Epoch  940/1000 Cost 0.021015 Acc 100.00%\n",
      "Epoch  950/1000 Cost 0.020810 Acc 100.00%\n",
      "Epoch  960/1000 Cost 0.020609 Acc 100.00%\n",
      "Epoch  970/1000 Cost 0.020412 Acc 100.00%\n",
      "Epoch  980/1000 Cost 0.020219 Acc 100.00%\n",
      "Epoch  990/1000 Cost 0.020029 Acc 100.00%\n",
      "Epoch 1000/1000 Cost 0.019843 Acc 100.00%\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr = 1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    hypothesis = model(x_train)\n",
    "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "\n",
    "        prediction = hypothesis >= torch.FloatTensor([0.5])\n",
    "\n",
    "        TPN = prediction.float() == y_train\n",
    "\n",
    "        acc = TPN.sum().item() / len(TPN)\n",
    "\n",
    "        print('Epoch {:4d}/{} Cost {:.6f} Acc {:2.2f}%'.format(\n",
    "            epoch, nb_epochs, cost.item(), acc * 100\n",
    "        ))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
